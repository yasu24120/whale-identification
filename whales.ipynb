{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, \\\n",
    "                            Activation, add, Add, Dropout, Concatenate, AveragePooling2D, GlobalAveragePooling2D, \\\n",
    "                            Reshape, Lambda, UpSampling2D,Layer\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import regularizers, metrics\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import zipfile\n",
    "import io\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "random_state = 42\n",
    "THRESHOLD = 0.05\n",
    "\n",
    "def resblock(x, filters=64, kernel_size=(3, 3), activation='relu'):\n",
    "    x_ = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x_ = BatchNormalization()(x_)\n",
    "    x_ = Conv2D(filters, kernel_size, padding='same')(x_)\n",
    "    x = Add()([x_, x])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def resblock2(x, filters=64, kernel_size=(3, 3), activation='relu'):\n",
    "    x = Conv2D(filters, (1,1), padding='same')(x) \n",
    "    x_ = BatchNormalization()(x)\n",
    "    x_ = Conv2D(filters, (1,1), padding='same')(x_)\n",
    "    x_ = BatchNormalization()(x_)\n",
    "    x_ = Activation(activation)(x_)\n",
    "    x_ = Conv2D(filters, kernel_size, padding='same')(x_)\n",
    "    x_ = BatchNormalization()(x_)\n",
    "    x_ = Activation(activation)(x_)\n",
    "    x_ = Conv2D(filters, (1,1), padding='same')(x_)\n",
    "    x_ = BatchNormalization()(x_)\n",
    "    x = Add()([x_, x])\n",
    "    return x\n",
    "\n",
    "def resnet2(x, filters=64, kernel_size=(3, 3), depth=10):\n",
    "    for i in range(depth):\n",
    "        x = resblock2(x, filters=filters)\n",
    "    return x\n",
    "\n",
    "def dense_block(x, input_channels, growth_rate, nb_blocks):\n",
    "    n_channels = input_channels\n",
    "    orig = x\n",
    "    for i in range(nb_blocks):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.1)(x) #Activation(\"relu\")(x)\n",
    "        x = Conv2D(128, (1, 1), kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.1)(x) #Activation(\"relu\")(x)\n",
    "        # フィルター数 = 成長度合\n",
    "        x = Conv2D(growth_rate, (3, 3), padding=\"same\", kernel_initializer='he_normal')(x)\n",
    "        # origと結合\n",
    "        x = Concatenate()([orig, x])\n",
    "        n_channels += growth_rate\n",
    "    return x, n_channels\n",
    "\n",
    "def transition_layer(x, input_channels, compression_factor=0.5):\n",
    "    n_channels = int(input_channels * compression_factor)\n",
    "    x = Conv2D(n_channels, (1, 1))(x)\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    return x, n_channels\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1-K.mean(f1)\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        eps =1e-12\n",
    "        y_pred = K.clip(y_pred, eps, 1.-eps)\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def darknet_block(x, input_channels):\n",
    "    ch_hid = input_channels//2\n",
    "    _x = x\n",
    "    x = Conv2D(ch_hid, (1,1), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.1)(x)\n",
    "    x = Conv2D(input_channels, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.1)(x)\n",
    "    x = Add()([x, _x])\n",
    "    return x\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    eps =1e-12\n",
    "    y_pred = K.clip(y_pred, eps, 1.-eps)\n",
    "    zero_weight= 0.2\n",
    "    one_weight=0.8\n",
    "    # Original binary crossentropy (see losses.py):\n",
    "    # K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "    # Calculate the binary crossentropy\n",
    "    b_ce = K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    # Apply the weights\n",
    "    weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "    weighted_b_ce = weight_vector * b_ce\n",
    "\n",
    "    # Return the mean error\n",
    "    return K.mean(weighted_b_ce)\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bounding boxの平均値とかを算出\n",
    "bounding_boxes = pd.read_csv(\"data/bounding_boxes.csv\", engine='python')\n",
    "\n",
    "#平均サイズを算出　(cnnのinputとして使う)\n",
    "bounding_boxes['x_size'] = bounding_boxes['x1'] - bounding_boxes['x0']\n",
    "bounding_boxes['y_size'] = bounding_boxes['y1'] - bounding_boxes['y0']\n",
    "average_xs = bounding_boxes['x_size'].mean()\n",
    "average_ys = bounding_boxes['y_size'].mean()\n",
    "print('x: ', average_xs, '  y: ', average_ys)\n",
    "\n",
    "#x:y = 3:1 =  くらいなので、300x100とする\n",
    "#なので、inputは100x300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bounding boxをdataに対応付ける\n",
    "data = pd.read_csv(\"data/train.csv\", engine='python') \n",
    "data = pd.merge(data, bounding_boxes, how=\"inner\" ,on=\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepareImages(data, m, dataset):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m,256, 256, 3))\n",
    "    count = 0   \n",
    "    for fig, x0, x1, y0, y1 in zip(data['Image'], data['x0'], data['x1'], data['y0'], data['y1']):\n",
    "        #load images into images of size 300x100x3\n",
    "        #print(fig, x0, x1)\n",
    "        im_pth = \"data/\"+dataset+\"/\"+fig\n",
    "        im = Image.open(im_pth)\n",
    "        im = im.convert('RGB')\n",
    "        #トリミングする\n",
    "        im = im.crop((x0, y0, x1, y1 ))  #left, upper, right, lower\n",
    "        im = im.resize((256, 256), Image.ANTIALIAS)\n",
    "        x = np.array(im)\n",
    "        X_train[count] = x/255\n",
    "        if count%5000== 0:\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "            #break\n",
    "        count += 1\n",
    "    return X_train.astype(np.float32)\n",
    "\n",
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    # print(y.shape)\n",
    "    return y, label_encoder\n",
    "\n",
    "def prepareDatasetForMoVAE(images, labels, label):\n",
    "    ret_x = []\n",
    "    for i in len(labels):\n",
    "        if labels[i] == label:\n",
    "            ret_x.append(images[i])\n",
    "    return np.array(ret_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, label_encoder = prepare_labels(data['Id'])\n",
    "\n",
    "#x_train = np.load('data/x_train_256x256_20190203.npy')\n",
    "x_train = prepareImages(data, len(data), 'train')\n",
    "np.save('data/x_train_256x256_20190201.npy', x_train)\n",
    "\n",
    "print(\"Done\")\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(latent_dim=64, n=16, k=32):\n",
    "    xin = Input(shape=(256,256,3,))\n",
    "    x = Conv2D(n, (1,1), kernel_initializer='he_normal')(xin)\n",
    "    x, n = dense_block(x, n, k, 2)\n",
    "    x, n = transition_layer(x, n)\n",
    "\n",
    "    x, n = dense_block(x, n, k, 4)\n",
    "    x, n = transition_layer(x, n)\n",
    "\n",
    "    x, n = dense_block(x, n, k, 8)\n",
    "    x, n = transition_layer(x, n)\n",
    "\n",
    "    x, n = dense_block(x, n, k, 4)\n",
    "    x, n = transition_layer(x, n)\n",
    "\n",
    "    h = GlobalAveragePooling2D()(x)\n",
    "    z_mean = Dense(latent_dim)(h) # 潜在変数の平均 μ\n",
    "    z_log_var = Dense(latent_dim)(h) #潜在変数の分散 σのlog\n",
    "\n",
    "    encoder_model = Model(xin, [z_mean, z_log_var])\n",
    "    return encoder_model\n",
    "\n",
    "def sampling(args, latent_dim=64):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(latent_dim,), mean=0.,\n",
    "                              stddev=1.0)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "def decoder_model(latent_dim=64, nch=64):\n",
    "    # Lambdaを使って式をwrap\n",
    "    zin = Input(shape=(latent_dim,))  \n",
    "    h = Dense(nch*64*64, kernel_initializer='glorot_normal')(zin)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    h = Reshape( [64, 64, nch] )(h) # 64*64*64 -> 64x64x64\n",
    "    h = UpSampling2D(size=(2, 2))(h) # 64x64x64 -> 128x128x64\n",
    "    h = Conv2D(int(nch/2), (3, 3), padding='same', kernel_initializer='glorot_uniform')(h) # 128x128x64 -> 128x128x32\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    h = UpSampling2D(size=(2, 2))(h) # 128x128x64 -> 256x256x64\n",
    "    h = Conv2D(int(nch/4), (3, 3), padding='same', kernel_initializer='glorot_uniform')(h) # 256x256x32 -> 256x256x16\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    h = Conv2D(int(nch/8), (3, 3), padding='same', kernel_initializer='glorot_uniform')(h) # 256x256x16 -> 256x256x8\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    h = Conv2D(3, (1, 1), padding='same', kernel_initializer='glorot_uniform')(h) # 256x256x8 -> 256x256x3\n",
    "    model_output = Activation('sigmoid')(h)\n",
    "    decoder_model = Model(zin, model_output)\n",
    "    return decoder_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_model()\n",
    "decoder = decoder_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_in = Input(shape=(256,256,3))\n",
    "[z_mean, z_log_var] = encoder(image_in)\n",
    "z = Lambda(sampling, output_shape=(64,))([z_mean, z_log_var])\n",
    "decoded_image = decoder(z)\n",
    "\n",
    "class CustomVariationalLayer(Layer): # Layer classの継承\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded):\n",
    "        original_dim = 128*128*3\n",
    "        xent_loss = original_dim * metrics.binary_crossentropy(K.flatten(x), K.flatten(x_decoded)) # 復元誤差: Reconstruction Error\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) # 正則化項: KL Divergence\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs) # Layer class のadd_lossを利用\n",
    "        return x # 実質的には出力は利用しない\n",
    "\n",
    "y = CustomVariationalLayer()([image_in, decoded_image])\n",
    "vae = Model(image_in, y) # xをinputにyを出力, 出力は実質関係ない\n",
    "vae.compile(optimizer='rmsprop', loss=None) # CustomVariationalLayerで追加したLossを利用するのでここでのlossはNoneとする\n",
    "\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(xs, batch_size=128):\n",
    "    #data augmentation\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "                iaa.Affine(rotate=(-45, 45),\n",
    "                        #translate_px={\"x\": (-40, 40), \"y\": (-40, 40)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        shear=(-5, 5)),\n",
    "                iaa.Fliplr(0.5)\n",
    "            ], random_order=True)\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "\n",
    "    n_batches = math.ceil(len(xs) / batch_size)\n",
    "    while True:   \n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = (i + 1) * batch_size\n",
    "            yield_image = []\n",
    "            for x in xs[start:end]:\n",
    "                yield_image.append(augment(x))\n",
    "            yield np.array(yield_image), None\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc1_interrupt = 'models/20190201_interrupt.h5'\n",
    "direc1 = 'models/20190201_checkpoint.h5'\n",
    "csv_logger = CSVLogger(\"models/20190201history.csv\")\n",
    "\n",
    "\n",
    "cb_es = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto')\n",
    "check_point = ModelCheckpoint(direc1, monitor='loss', \n",
    "                              verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_gen = generateData(x_train, batch_size=batch_size)\n",
    "stepsPepoch = math.ceil(len(x_train) / batch_size)\n",
    "\n",
    "try:\n",
    "    keras_history = vae.fit_generator(train_gen,\n",
    "                        steps_per_epoch=stepsPepoch, \n",
    "                        epochs=1000, \n",
    "                        callbacks=[cb_es, check_point, csv_logger], \n",
    "                        verbose=1)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"keyboard interrupted\")\n",
    "    model.save(direc1_interrupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
